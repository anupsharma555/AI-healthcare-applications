{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updated Inference.ipynb notebook implements a robust pipeline for automated chest X-ray inference using a trained deep learning model. It loads and validates DICOM files, ensuring only chest X-rays with appropriate modality and body part are processed. Images are preprocessed (including resizing and normalization) to match the modelâ€™s input requirements, and predictions are made using the loaded model architecture and weights. The notebook outputs, interpretable results for each test DICOM, skipping and logging any files that do not meet validation criteria, and allows for easy adjustment of the decision threshold based on prior model evaluation. This workflow demonstrates a practical, reproducible approach for clinical AI inference and regulatory review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Python version: 3.7.6\n",
      "PyDICOM version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    " #Import necessary libraries\n",
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Medical imaging imports\n",
    "import pydicom\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress TensorFlow and warning messages\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Print versions for documentation\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyDICOM version: {pydicom.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "\n",
    "def check_dicom(filename): \n",
    "    try:\n",
    "        ds = pydicom.dcmread(filename)\n",
    "        # Check modality is X-ray (DX)\n",
    "        if ds.Modality != 'DX':\n",
    "            print(f\"File {filename}: Not an X-ray (Modality={ds.Modality})\")\n",
    "            return None\n",
    "            \n",
    "        # Check body part is chest\n",
    "        if hasattr(ds, 'BodyPartExamined') and ds.BodyPartExamined.lower() != 'chest':\n",
    "            print(f\"File {filename}: Not a chest X-ray (BodyPartExamined={ds.BodyPartExamined})\")\n",
    "            return None\n",
    "            \n",
    "        # Check image position (if available)\n",
    "        if hasattr(ds, 'PatientPosition'):\n",
    "            print(f\"Image Position: {ds.PatientPosition}\")\n",
    "            if ds.PatientPosition not in ['PA', 'AP']:\n",
    "                print(f\"Warning: Unexpected patient position: {ds.PatientPosition}\")\n",
    "                \n",
    "        # Additional DICOM info for validation\n",
    "        print(f\"Image Type: {ds.get('ImageType', 'Not specified')}\")\n",
    "        print(f\"Patient Position: {ds.get('PatientPosition', 'Not specified')}\")\n",
    "            \n",
    "        img = ds.pixel_array\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_mean, img_std, img_size): \n",
    "    # Resize image if needed\n",
    "    from cv2 import resize, INTER_LINEAR\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)  # Convert grayscale to 3-channel\n",
    "    img_resized = resize(img, (img_size[2], img_size[1]), interpolation=INTER_LINEAR)\n",
    "    img_resized = img_resized.astype(np.float32)\n",
    "    # Normalize\n",
    "    img_norm = (img_resized - img_mean) / img_std\n",
    "    # Add batch dimension\n",
    "    proc_img = np.expand_dims(img_norm, axis=0)\n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # Load model architecture\n",
    "    with open(model_path, \"r\") as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # Load weights\n",
    "    model.load_weights(weight_path)\n",
    "    # Compile (use same loss/metrics as training)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    prob = model.predict(img)[0][0]\n",
    "    prediction = int(prob > thresh)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model files...\n",
      "Architecture file exists: True\n",
      "Weights file exists: True\n",
      "Checking model files...\n",
      "Architecture file exists: True\n",
      "Weights file exists: True\n",
      "\n",
      "Loading model architecture...\n",
      "Architecture loaded in 0.00s\n",
      "\n",
      "Creating model from architecture...\n",
      "Model created in 0.15s\n",
      "\n",
      "Loading model weights...\n",
      "Weights loaded in 0.11s\n",
      "\n",
      "Compiling model...\n",
      "Model compilation complete\n"
     ]
    }
   ],
   "source": [
    "# Add imports for better diagnostics\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Define model file paths first\n",
    "model_path = \"my_model_architecture.json\"\n",
    "weight_path = \"xray_class_my_model.best.hdf5\"\n",
    "\n",
    "# Now check if files exist\n",
    "print(\"Checking model files...\")\n",
    "print(f\"Architecture file exists: {os.path.exists(model_path)}\")\n",
    "print(f\"Weights file exists: {os.path.exists(weight_path)}\")\n",
    "\n",
    "# Verify files exist first\n",
    "print(\"Checking model files...\")\n",
    "print(f\"Architecture file exists: {os.path.exists(model_path)}\")\n",
    "print(f\"Weights file exists: {os.path.exists(weight_path)}\")\n",
    "\n",
    "# Load model with timing and verbose output\n",
    "try:\n",
    "    print(\"\\nLoading model architecture...\")\n",
    "    start_time = time.time()\n",
    "    with open(model_path, \"r\") as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    print(f\"Architecture loaded in {time.time() - start_time:.2f}s\")\n",
    "    \n",
    "    print(\"\\nCreating model from architecture...\")\n",
    "    start_time = time.time()\n",
    "    my_model = model_from_json(loaded_model_json)\n",
    "    print(f\"Model created in {time.time() - start_time:.2f}s\")\n",
    "    \n",
    "    print(\"\\nLoading model weights...\")\n",
    "    start_time = time.time()\n",
    "    my_model.load_weights(weight_path)\n",
    "    print(f\"Weights loaded in {time.time() - start_time:.2f}s\")\n",
    "    \n",
    "    print(\"\\nCompiling model...\")\n",
    "    my_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model compilation complete\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during model loading: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Position: PA\n",
      "Image Type: Not specified\n",
      "Patient Position: PA\n",
      "test1.dcm: Prediction = 0\n",
      "Image Position: AP\n",
      "Image Type: Not specified\n",
      "Patient Position: AP\n",
      "test2.dcm: Prediction = 1\n",
      "Image Position: AP\n",
      "Image Type: Not specified\n",
      "Patient Position: AP\n",
      "test3.dcm: Prediction = 1\n",
      "File test4.dcm: Not a chest X-ray (BodyPartExamined=RIBCAGE)\n",
      "Skipping test4.dcm: not a valid chest X-ray.\n",
      "File test5.dcm: Not an X-ray (Modality=CT)\n",
      "Skipping test5.dcm: not a valid chest X-ray.\n",
      "Image Position: XX\n",
      "Warning: Unexpected patient position: XX\n",
      "Image Type: Not specified\n",
      "Patient Position: XX\n",
      "test6.dcm: Prediction = 0\n"
     ]
    }
   ],
   "source": [
    "# Make sure all functions are defined above this cell!\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "def preprocess_image(img, img_mean, img_std, img_size): \n",
    "    # Convert grayscale to 3-channel if needed\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "    # Resize image to (height, width)\n",
    "    img_resized = resize(img, (img_size[1], img_size[2]), preserve_range=True, anti_aliasing=True)\n",
    "    img_resized = img_resized.astype(np.float32)\n",
    "    # Normalize\n",
    "    img_norm = (img_resized - img_mean) / img_std\n",
    "    # Add batch dimension\n",
    "    proc_img = np.expand_dims(img_norm, axis=0)\n",
    "    return proc_img\n",
    "\n",
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = \"my_model_architecture.json\"\n",
    "weight_path = \"xray_class_my_model.best.hdf5\"\n",
    "IMG_SIZE = (1, 224, 224, 3)\n",
    "img_mean = 128.0\n",
    "img_std = 64.0\n",
    "thresh = 0.1  # Use your chosen threshold\n",
    "\n",
    "my_model = load_model(model_path, weight_path)\n",
    "\n",
    "for i in test_dicoms:\n",
    "    img = check_dicom(i)\n",
    "    if img is None:\n",
    "        print(f\"Skipping {i}: not a valid chest X-ray.\")\n",
    "        continue\n",
    "    img_proc = preprocess_image(img, img_mean, img_std, IMG_SIZE)\n",
    "    pred = predict_image(my_model, img_proc, thresh)\n",
    "    print(f\"{i}: Prediction = {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
